# Algorithms

Repo for algorithms and data structures on Java

### Жадные алгоритмы

Жадные алгоритмы как правило решают оптимизационные задачи и на каждом шаге делают некоторый
наиболее очевидный шаг, так называемый жадный шаг, таким образом строят оптимальное решение.

#### Пример. Покрытие точек отрезками.

Есть множество n точек на прямой. Необходимо покрыть все точки
минимальным количеством отрезков единичной длины.    
Надежный шаг - это добавить отрезок, левый конец которого совпадает с самой крайней левой точкой.
Мы заранее знаем, что это оптимальный шаг. Так как есть множество оптимальных решений, то мы
выбираем одно из них, которе описано в надежном шаге.    
Решение - выполнять надежный шаг на каждой итерации цикла, при этом забывая те точки которые
покрыли отрезком.
Сложность O(n^2)

#### Пример. Необходимо взять максимальное количество вершин не соединенных ребром.

Надежный шаг - существует оптимальное решение, которое содержит все листья дерева, то есть все
вершины, у которых нет, дочерних вершин.

#### Пример. Задача о непрерывном рюкзаке

Есть веса w1...wn и стоимости предметов c1...cn. А так же вместимость рюкзака W. Необходимо
узнать суммарную стоимость ЧАСТЕЙ всех предметов в рюкзаке, вес которых не превышает W. То есть
можно предмет разделить на часть, при этом стоимость и вес его пропорционально изменятся.    
Надежный шаг - существует оптимальное решение, содержащее максимально возможную часть предмета,
**стоимость которого за килограмм максимальна**. То есть надо использовать по максимома самый
дорогой предмет.

#### Коды Хаффмана

Оптимальный бинарный код для сжатия строки.

##### Пример.

На вход подается строка и мы хотим каждому ее символу присвоить бинарный код так, что бы после
того как каждый символ заменили на его бинарный код получилась как можно более короткая бинарная
строчка. Оптимизация - попытаться часто используемому символу присвоить более короткий код.
Свойство - код называется **беспрефиксными**, если никакой код символа не является префиксом другого
кода символа. Это значит, что ни один код символа не является префиксом кода другого символа,
таким образом когда мы будем читать коды мы всега однозначно будем понимать, что это за символ.
Беспрефиксными коды удобно представлять в двоичном дереве.    
Частота некорневой вершины назовем количество раз, которое вершина будет посещена в процессе
кодировки\декодировки. Таким оразом мы ищем строго двоичное дерево с минимальной суммой пометок
в вершинах, в котором листья помечены входными частотами, а внутренние вершины - суммами
пометок их детей. Две минимальные частоты будут листьями на самом нижнем уровне и можно считать,
что они братья. Надежный шаг - выбрать две минимальные частоты fi и fj, сделать их детьми новой
вершины с пометкой fi+fj; выкинуть частоты fi и fj, добавить fi + fj.

#### Очереди с приоритетами

Очереди обладают методами:

1) Добавление элемента в очередь
2) Извлечение элемента с минимальным приоритетом
3) Извлечение элемента на который указывает итератором

Наивная реализация очередей с приоритетами - через массив.

1) Неупорядоченный массив. Доступ к элементу O(n)
2) Упорядоченный массив. Доступ к элементу с минимальным приоритетом за O(1), но удаление
   элемента по индексу приведет к сдвигу в массиве, и может быть время O(n)
3) Упорядоченный связанный список. Доступ к минимальному элементу за O(1), удаление O(1), но
   добавление элемента за O(n)

Правильная реализация - куча.
Куча - это двоичное дерево. Свойства кучи:

1) Значение вершины <= значений ее детей
2) Минимальное значение хранится в корне дерева. поэтому получение минимального значение
   выполняется за O(n). В таком случае куча называется MIN куча.
   Для MAX кучи свойства звучат наоборот MIN куче.

Операции на деревом:

1) Добавление нового элемента. Добавление элемента - подвешиваем его листом в какую-нибудь
   вершину. Таким образом нарушается свойство 1) кучи. Поэтому надо просеить кучу, то есть
   починить дерево.

**Просеивание кучи вверх:**    
Дальше поменяем ноду с новым элементом на ее родительскую ноду, проверяем,
что дерево починилось, если нет, то повторяем просеивание - меняем местами новую новую ноду и
родительскую.

**Время работы операции вставки:**

- В каждый момент времени свойство кучи нарушено не более чем в одной вершине.
- При просеивании вверх вершина становится ближе к корню
- Время работы O(h), где h - это высота кучи

2) Извлечение минимума. Мы извлекаем корень дерева, но на его место надо кого-нибудь поставить
   на корень. Свойство кучи может нарушиться, то есть корень может быть больше чем его дети. Для
   починки надо просеить кучу вниз.

**Просеивание кучи вниз:**    
Можем менять проблемную вершину с одним из ее детей. Надо выбрать только того ребенка, который  
меньше другого. Таким образом мы знаем, что чинить дерево придется только в одной из его
поддеревьев. Время работы O(h)

3) Изменение приоритета. при изменении приоритета элемента мы проверяем, если новый приоритет
   меньше, чем был раньше, то надо просеивать вверх, если больше чем был, то надо просеивать вниз
4) Удаление. Для удаления надо изменить приоритет элемента на минус бесконечность или на ту
   которой гарантированно нет в нашей куче, просеить элемент наверх, то есть в корень и дальше
   извлечь минимум. Дальнейшие действия определяются свойствами извлечения минимума.

**Полные двоичные деревья**    
Это такие деревья у которого заполнены все уровни, кроме может быть последнего. Последний
уровень заполнен слева направо, но может быть не до конца. Мы представляем,
что заполняем дерево так: сначала корень, потом следующий уровень слева направо и дальше. Таком
образом дерево может быть представлено в виде массива.     
Свойство - если у вершины индекс i, то у ее детей будут индексы слева направо 2i и 2i+1, а ее
родитель будет иметь индекс i/2 формально округленный. То есть если i = 5, то дети имеют индексы
10 и 11, а родитель 2.

Резюмируя:

1) деревья у которого заполнены все уровни, кроме может быть последнего. Последний
   уровень заполнен слева направо, но может быть не до конца.
2) Естественная нумерация вершин сверху вниз и слева направо.
3) При добавлении элемента подвешиваем лист на последний уровень. А при удалении отрезаем самый
   последний лист.
4) Индексы - если у вершины индекс i, то у ее детей будут индексы слева направо 2i и 2i+1, а ее
   родитель будет иметь индекс i/2 формально округленный. При вычислении данных индексов надо
   проверять, что они попадают в отрезок [1,n], где n - размер кучи.
5) Не нужно хранить указатели на родителей и детей
6) Глубина кучи есть O(log n), что означает, что все операции над кучей будут выполняться за
   время O(log n)

### Разделяй и властвуй

Общая идея - для того что бы решить задач - разбираем задачу на несколько более простых
подзадач. Далее решаем эти подзадачи рекурсивно. И из полученных ответов для подзадач строится
ответ для исходной подзадачи.

#### Поиск в неупорядоченном массиве

Естественный алгоритм - линейный поиск, который сканирует 1 раз массив. Сложность O(n). Любой
алгоритм, который не прочитал весь массив не может с уверенностью сказать, что ключа k в массиве
нет.

#### Поиск в упорядоченном массиве

Двоичный поиск. На каждом шаге цель уменьшить область поиска в два раза. Если ищем в массиве
значение k, то первым делом сравниваем это значение со средним значением в массиве (тот, что в
середине массива). Если он меньше, то точно знаем, что k в левой части, и наоборот, если больше.
Вводим два индекса, который будут задавать текущий отрезок в массиве. Изначально l = 1, r = n.
Ищем средний элемент массива m = (l+r)/2 (floor) или l + (r-l)/2, что бы не было переполнения типов.
Если m совпадает с k, то возвращаем его, если меньше, то r = m - 1, иначе l = m + 1.    
Сложность - O(log n) на каждом шаге размер отрезка уменьшается вдвое.

#### Умножение чисел

В столбик умножать (O(n)) - не оптимально.
Сложение в двоичной системе счисление. Идем с младшего бита к старшему (справа налево).    
При умножении в двоичной системе счисления так же идем справа налево. Надо умножить младший бит
(цифра) второго числа на все биты (цифры) другого числа. При этом каждый следующий этап
умножения - добавляет сдвиг налево. В итоге получим в столбик столько последовательностей битов,
сколько раз умножали цифру одного числа на все цифры другого со сдвигами налево. После чего
складываем результат. Всего будет n сложений. Максимальный сдвиг не больше 2n. Сложность
квадратична O(n^2).

##### Рекуррентная формула 1

- y = 2 * (int) Math.floor(y/2) если y четное
- y = 1 + 2 * (int) Math.floor(y/2) если y нечетное

Домножим все на x

- x * y = 2 * (x * (int) Math.floor(y/2)), если y четное
- x * y = x + 2 * (x * (int) Math.floor(y/2)), если y нечетное

y/2 округленное вниз - это число y с отброшенным последним битом

Функция multiply    
Вход - два n-битовых целых числа x>=0 и y>=0. Где n - это длина максимального из чисел. Будем
считать, что числа одинаковой длины, просто дописав достаточное количество нулей спереди.    
Выход - результат умножения двух чисел.

Если y = 0:    
вернуть 0    
z = multiply(x, (int) Math.floor(y/2))    
если y четно:    
вернуть 2z    
иначе:    
вернуть x + 2z

Сложность - O(n^2) - не более чем n рекурсивных вызовов, и в каждом вызове делается линейная работа.

##### Рекуррентная формула 2

Данная формула позволит получить квадратичный алгоритм, который можно будет улучшить так, что бы
он работал асимптотически быстрее чем O(n^2)

Надо разбить числа на две части.

1) x = x_L и x_R = 2^(n/2) * x_L + y_R
2) y = y_L и y_R = 2^(n/2) * y_L + y_R
3) x * y = (2^(n/2) * x_L + x_R) * (2^(n/2) * y_L + y_R) = 2^n * x_L * y_L + 2^(n/2) * (x_L *
   y_R + x_R * y_L) + x_R * y_R

Сложность = T(n) = 4T(n/2) + O(n), где 4T - это обработка четырех рекурсивных вызовов.

##### Улучшенная рекуррентная формула 2

Вместо четырех рекурсивных вызовов для вычисления x_L * y_L, x_L * y_R, x_R * y_L, x_R * y_R
сделаем ти вычисления x_L * y_L, x_R * y_R и (x_L + x_R) * (y_L + y_R)    
Тогда (x_L * y_R + x_R * y_L) = (x_L + x_R) * (y_L + y_R) - x_L * y_L - x_R * y_R    
Сложность - T(n) = 3T(n/2) + O(n)

Алгоритм Карацуба

**karatsuba(x, y)**    
Вход - целые числа x,y >= 0 в двоичной записи. n максимальный размер числел    
Выход - результат умножения x*y

n = max(размер x, размер y)    
если n = 1: вернуть xy

x_L, x_R = левые n/2 округлением вверх, правые n/2 округлением вниз битов x    
y_L, y_R = левые n/2 округлением вверх, правые n/2 округлением вниз битов y

P1 = karatsuba(x_L, y_L)    
P2 = karatsuba(x_R, y_R)    
P3 = karatsuba(x_L + x_R, y_L + y_R)

вернуть P1 * 2^(n/2 округленную вниз) + (P3 - P1 - P2) * 2(n/2 округленную вниз) + P2

Сложность - O(n^1.6). Есть еще быстрее алгоритмы основанные на быстром преобразовании Фурье.

#### Произведение матриц

Считаем, что матрицы квадратные и одного размера
Умножение матриц - надо каждую строчку (i) одной матрицы домножить на каждый столбец (j) другой
матрицы, при этом должно получится одно значение, которое попадет в (i, j) элемент матрицы
произведения. Как этого достичь? Надо (i1 * j1) + (i2 * j2) + ...     
Сложность - O(n^3)

Даны две матрицы с размером n = 2 X и Y.
Данная формула верна и в случае, когда X и Y - это матрицы размера nxm, а Xij, Yij - это их
подматрицы размера n/2 x n/2. То есть по сути опять разбиваются матрицы на две 4 части и
происходит перемножение подматриц. Время работы T(n) = 8T(n/2) + O(n^2). То есть делаем 8
вызовов рекурсивных по умножению матриц.

**Алгоритм Штрассена**

Если XY = {

|                 |                 |
|-----------------|-----------------|
| X11Y11 + X12Y21 | X11Y12 + X12Y22 |
| X21Y11 + X22Y21 | X21Y12 + X22Y22 |

}

То применив алгоритм Штрассена получим:    
XY = {

|             |             |
|-------------|-------------|
| P5+P4-P2-P6 | P1+P2       | 
| P3+P4       | P1+P5-P3-P7 |

}

P1 = X11(Y21 - Y22)    
P2 = (X11 + X12)Y22    
P3 = (X21 + X22)Y11    
P4 = X22(Y21 - Y11)    
P5 = (X11 + X22)(Y11 + Y22)    
P6 = (X12 - X22)(Y21 + Y22)    
P7 = (X11 - X21)(Y11 + Y12)

Сложность - O(n^(log2_7)) = O(n^2.807)

Алгоритмы умножения матриц используются в алгоритмах на графах. Например, что бы узнать есть ли
треугольник (три вершины соединенные ребром). Стандартный способ это сделать - написать матрицу
смежности и возвести ее в куб.

#### Сортировка слиянием

На вход дается массив A[1..n] . На выходе **перестановка** A'[1..n] элементов массива A[1..n], в
который элементы упорядочены по убыванию: A'[1] <= A'[2] <= .. <= A'[n]

Алгоритм имеет доступ к оракулу сравнения. Считаем, что сравнение занимает константное время.    
Если A = A', то алгоритм сортирует на месте, то есть не использует дополнительной памяти.

Оракул сравнения - внешняя процедура.

##### Наивный алгоритм - сортировка вставками.

для i от 2 до n:    
j = i    
пока j>1 и A[j] < A[j-1]:    
обменять A[j] и A[j-1]    
j = j-1

То есть для каждого слудующего элемента в массиве проверяем, если эоемент больше предыдущего, то
ок, если меньше, то гоним этот элемент налево до тех пор пока текущий элемент (j) не будет больше
предыдущего (j-1). Таким образом все элементы от начала до j будут отсортированы. Массив
сортируется на месте.    
Сложность - O(n^2).

##### Сортировка слиянием

mergesort(A, l, r)    
если l < r:    
m = (l+r)/2 округленный вниз    
merge(mergesort(A,l,m), mergesort(A, m+1, r))

Сортировка различных кусков массива рекурсивно. Алгоритм делает хоть, что-то только с массивом
размером больше двух. Есть массив, надо отсортировать в нем кусок от l до r, вычисляем индекс
среднего элемента, после этого делается отдельный рекурсивный вызов для куска слева и справа.
После этого надо сделать слияние результатов процедурой merge.   
Процедура merge:

* сливает два упорядоченных массива в один
* Работает за линейное от суммы размеров данных двух массивов: первым элементом
  результирующего массива будет меньший из первых элементов данных массивов, оставшаяся часть
  может быть заполнена рекурсивно. То есть два массива, смотрим на первый элемент этих двух
  массивов и берем минимальный из них и добавляем его в новый массив. **О добавленном элементе
  забываем. Таким образом можно всегда брать первый элемент в массивах и их сравнивать на каждой
  итерации** Повторяем до тех пор пока оба массива не пустые. Когда один массив стал пустым, а
  второй нет, то просто остатки дописываются в конец к результирующему массиву, так как массивы
  может быть разной длины.

Сложность - O(n log n)

**Итеративная сортировка слиянием:**        
функция intertivemergesort(A[1..n])    
Q = [] пустая очередь    
для i от 1 до n:    
pushback(Q, [A[i]])    
пока |Q| > 1:    
pushback(Q, merge(popfront(Q), popfront(Q)))    
вернуть popfront(Q)

_pushback(Q, [A[i]])_ - кладем все элементы в очередь в виде одноэлементных массивов    
_pushback(Q, merge(popfront(Q), popfront(Q)))_ - достаем из начала очереди два элемента, эти два
элемента сливаются, и после этого слитые два массива в виде массива побольше кладутся в конец
очереди. И так делает сначала для массивов с одним элементом, потом с двумя и так далее.

Лемма - любой корректный алгоритм сортировки, основанный на сравнениях элементов, делает Omega(n
log n ) сравнений в худшем случае на массив размера n.

**Заключение**

1) Наивный алгоритм сортировки имеет время работы O(n^2)
2) алгоритм сортировки слиянием, основанный на методе разделяй и властвуй, работает за время O(n
   log n). Использует O(n) дополнительной памяти для слияние массивов.
3) Любой алгоритм, сортирующий сравнениями, в худшем случае делает Omega(n log n) сравнений.
   Поэтому алгоритм сортировки слиянием асимптотически оптимален